\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\select@language {english}
\select@language {english}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Transformation between coordinate systems\relax }}{6}{figure.caption.16}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Rotation about x-axis by angle $\alpha $\relax }}{7}{figure.caption.17}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Transformation from $S_a$ to $S_b$\relax }}{9}{figure.caption.18}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Pinhole camera model\relax }}{11}{figure.caption.19}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Real image plane, symmetrical image plane and normalized imaging plane\relax }}{11}{figure.caption.20}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Image plane coordinate system\relax }}{13}{figure.caption.21}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Image projection relationship\relax }}{14}{figure.caption.22}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Four coordinate systems and their relationships\relax }}{15}{figure.caption.23}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Image coordinate with 480 height and 640 width\relax }}{16}{figure.caption.24}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Derivative\relax }}{17}{figure.caption.25}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Minimize cost function $J(\theta _0,\theta _1)$ with gradient descent\relax }}{18}{figure.caption.26}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Four Object points and their corresponding projection points in image plane with noisy, using least squares method to calculate the optimal camera post \textbf {R}, \textbf {t}\relax }}{20}{figure.caption.27}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Marker-based(\textbf {MA}) pose estimation and markerless environment(\textbf {MAL-VO}) pose estimation\cite {acuna2017moma}.\relax }}{23}{figure.caption.28}
\contentsline {figure}{\numberline {7.2}{\ignorespaces Two-robot caterpillar. At the beginning, the robot with camera is static and the robot with marker is mobile. And then, the marker and camera exchange states which means move in turns, now the camera is mobile and marker is static. Finally, we can get the pose estimation between them\cite {acuna2017moma}.\relax }}{24}{figure.caption.29}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {8.1}{\ignorespaces Accuracy as a function of camera distance and relative camera angle\cite {abawi2004accuracy}\relax }}{26}{figure.caption.30}
\contentsline {figure}{\numberline {8.2}{\ignorespaces Error for camera distance and rotation angle\cite {pentenrieder2006analysis}\relax }}{27}{figure.caption.31}
\contentsline {figure}{\numberline {8.3}{\ignorespaces One simple example for the form of accuracy function, the influencing factors could be the camera intrinsic parameters; camera extrinsic parameters; the size of planar marker; the position of camera and so on\relax }}{28}{figure.caption.32}
\contentsline {figure}{\numberline {8.4}{\ignorespaces The detection region of the marker is defined as a semicircle with radius 3 meter, the $3m \times 6m$ rectangle region is grid-based and each cell is $0.1m \times 0.1m$, this region would be converted into a $30 \times 60$ matrix.\relax }}{28}{figure.caption.33}
\contentsline {figure}{\numberline {8.5}{\ignorespaces The blue square represents one cell and each blue circle represents one camera position. Condition number of this cell: $c = mean(c_1 + c_2 +c_3 + c_4)$\relax }}{29}{figure.caption.34}
\contentsline {figure}{\numberline {8.6}{\ignorespaces An simple example of condition number distribution matrix, which is a $30 \times 60$ matrix, the above only shows part of the condition number distribution matrix\relax }}{29}{figure.caption.35}
\contentsline {figure}{\numberline {8.7}{\ignorespaces Process...TODO\relax }}{30}{figure.caption.36}
\contentsline {figure}{\numberline {8.8}{\ignorespaces Homography matrix\relax }}{31}{figure.caption.37}
\contentsline {figure}{\numberline {8.9}{\ignorespaces Normalization of 4 image points, this process can reduce condition number of matrix \texttt {A} and maximize the robustness of the DLT homography estimation against noise\relax }}{33}{figure.caption.38}
\contentsline {figure}{\numberline {8.10}{\ignorespaces The perspective projection of the 3D plane\relax }}{35}{figure.caption.39}
\contentsline {figure}{\numberline {8.11}{\ignorespaces A marker with size $0.3m \times 0.3m$, four features at each corner.\relax }}{36}{figure.caption.41}
\contentsline {figure}{\numberline {8.12}{\ignorespaces Invert camera and marker\relax }}{37}{figure.caption.43}
\contentsline {figure}{\numberline {8.13}{\ignorespaces Two-robot Caterpillar\relax }}{37}{figure.caption.44}
\contentsline {figure}{\numberline {8.14}{\ignorespaces Camera distribution\relax }}{38}{figure.caption.45}
\contentsline {figure}{\numberline {8.15}{\ignorespaces Colormap \textit {magma} from \textit {matplotlib} library\relax }}{40}{figure.caption.46}
\contentsline {figure}{\numberline {8.16}{\ignorespaces Condition number distribution of different camera positions, each circle represents each camera position, different colors represent different values(figure \ref {fig:magma})\relax }}{41}{figure.caption.47}
\contentsline {figure}{\numberline {8.17}{\ignorespaces Condition number distribution(Interaction of \texttt {angle} and \texttt {height}), object points and image points are not normalized. The camera distribution is on YZ plane. The \texttt {angle} $\theta = [\SI {0}{\degree }, \SI {180}{\degree }]$, the step of angle is $\SI {5}{\degree }$, but in real world the angle can not be $\SI {0}{\degree }$ because of the constrain of DLT(three points that must be not collinear). The \texttt {height}(distance between camera and marker) as radius $ r= [0.1m, 3.0m]$, the step of radius is $0.1m$.\relax }}{42}{figure.caption.48}
\contentsline {figure}{\numberline {8.18}{\ignorespaces Symmetrical camera positions with different condition number\relax }}{43}{figure.caption.49}
\contentsline {figure}{\numberline {8.19}{\ignorespaces When theta is equal to $\SI {0}{\degree }$ or $\SI {180}{\degree }$, image points exactly same. When theta closes to 90, image points exactly very similar. When theta closes to $\SI {45}{\degree }$ or $\SI {135}{\degree }$, image points have relative larger differences\relax }}{44}{figure.caption.50}
\contentsline {figure}{\numberline {8.20}{\ignorespaces Condition number distribution of different camera positions, each circle represents each camera position, different colors represent different values(figure \ref {fig:magma})\relax }}{46}{figure.caption.51}
\contentsline {figure}{\numberline {8.21}{\ignorespaces Condition number distribution, object points and image points are both regular normalized\relax }}{47}{figure.caption.52}
\contentsline {figure}{\numberline {8.22}{\ignorespaces Test\relax }}{48}{figure.caption.53}
\contentsline {figure}{\numberline {8.23}{\ignorespaces Normalization\relax }}{48}{figure.caption.54}
\contentsline {figure}{\numberline {8.24}{\ignorespaces Condition number distribution, object points are regular normalized and image points are normalized only with translation but no scaling(scale = 1)\relax }}{49}{figure.caption.55}
\contentsline {figure}{\numberline {8.25}{\ignorespaces Condition number distribution of different camera positions, each circle represents each camera position, different colors represent different values(figure \ref {fig:magma})\relax }}{50}{figure.caption.56}
\contentsline {figure}{\numberline {8.26}{\ignorespaces Condition number distribution, object points are regular normalized and image points are normalized only with translation but no scaling(scale = 1), but $condition number = 1/condition number $\relax }}{51}{figure.caption.57}
\contentsline {figure}{\numberline {8.27}{\ignorespaces Condition number distribution of different camera positions, each circle represents each camera position, different colors represent different values(figure \ref {fig:magma})\relax }}{52}{figure.caption.58}
\contentsline {figure}{\numberline {8.28}{\ignorespaces Condition number distribution, object points are regular normalized and image points are normalized with $scale = radius*np.sqrt(2) / meandist$\relax }}{53}{figure.caption.59}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {9.1}{\ignorespaces Probability density function of 2 dimensional Gaussian distribution\relax }}{55}{figure.caption.60}
\contentsline {figure}{\numberline {9.2}{\ignorespaces Confidence ellipses for normally distributed data with different confidence levels\cite {vincent_spruyt}\relax }}{57}{figure.caption.62}
\contentsline {figure}{\numberline {9.3}{\ignorespaces Visualization of covariance ellipsoid for a certain confidence level\cite {bauer2007tracking}\relax }}{58}{figure.caption.63}
\contentsline {figure}{\numberline {9.4}{\ignorespaces Setup for analyzing the theoretical accuracy of a monocular tracking system with planar fiducials\cite {bauer2007tracking}\relax }}{60}{figure.caption.66}
\contentsline {figure}{\numberline {9.5}{\ignorespaces Rotation in spherical coordinate system\relax }}{61}{figure.caption.67}
\contentsline {figure}{\numberline {9.6}{\ignorespaces Accuracy of the pose of the camera in marker coordinates. Display with covariance ellipsoids\cite {bauer2007tracking}\relax }}{63}{figure.caption.68}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {10.1}{\ignorespaces Configuration space of a point-sized robot. White = $C_{free}$, gray = $C_{obs}$, green point = Start, blue point = Goal\cite {wiki_motion_planning}.\relax }}{64}{figure.caption.69}
\contentsline {figure}{\numberline {10.2}{\ignorespaces Convert configuration space into a $3m \times m$ grid. The center of the marker is at $(0,3m)$ in world coordinates\relax }}{65}{figure.caption.70}
\contentsline {figure}{\numberline {10.3}{\ignorespaces Rotational error and translational error for the selected \texttt {IPPE} method\cite {collins2014infinitesimal}\relax }}{66}{figure.caption.71}
\contentsline {figure}{\numberline {10.4}{\ignorespaces Rotational error and translational error for the selected \texttt {LM} and \texttt {EPnP} methods\cite {lepetit2009epnp}\relax }}{66}{figure.caption.72}
\contentsline {figure}{\numberline {10.5}{\ignorespaces Rotational error and translational error for the selected \texttt {DLS} method\relax }}{67}{figure.caption.73}
\contentsline {figure}{\numberline {10.6}{\ignorespaces Calculated path with \texttt {A*} search algorithm on grid. The robot can move in 8 directions(\texttt {Diagonal distance} as heuristic function)\cite {AHeuristic}.\relax }}{68}{figure.caption.74}
\contentsline {figure}{\numberline {10.7}{\ignorespaces Attractive potential fields + repulsive potential fields = Total potential fields\cite {choset2010robotic}\relax }}{69}{figure.caption.75}
\contentsline {figure}{\numberline {10.8}{\ignorespaces Artificial potential fields method in our situation, in this figure the start is $(1.55m,2.05m)$ and the goal is $(1.55m,4.05m)$.\relax }}{70}{figure.caption.76}
\contentsline {figure}{\numberline {10.9}{\ignorespaces Artificial potential fields method in our situation\relax }}{71}{figure.caption.77}
\contentsline {figure}{\numberline {10.10}{\ignorespaces Start point: (1.55m,2.05m), goal point: (1.55m,4.05m). The center of the planar marker is at (0,3m). Blue line: path computed with \texttt {A*}, red line: path computed with artificial potential fields method. Each point means each step on the path.\relax }}{72}{figure.caption.78}
\contentsline {figure}{\numberline {10.11}{\ignorespaces The blue intervals and red intervals represent the mean error(euclidean distance) between desired paths and measured paths\relax }}{72}{figure.caption.79}
\contentsline {figure}{\numberline {10.12}{\ignorespaces Compare the errors of paths computed with \texttt {A*} and artificial potential fields method\relax }}{73}{figure.caption.80}
\contentsline {figure}{\numberline {10.13}{\ignorespaces Blue line: Mean error of \texttt {A*} computed path, red line: mean error of artificial potential fields computed path. At each point represents the standard deviation of the error.\relax }}{73}{figure.caption.81}
\contentsline {figure}{\numberline {10.14}{\ignorespaces Blue line: Rotational error and translational error of path computed with \texttt {A*}, red line: Rotational error and translational error of path computed with artificial potential fields method. At each point represents the error standard deviation.\relax }}{74}{figure.caption.82}
\contentsline {figure}{\numberline {10.15}{\ignorespaces Compare the rotational errors of paths computed with \texttt {A*} and artificial potential fields method\relax }}{74}{figure.caption.83}
\contentsline {figure}{\numberline {10.16}{\ignorespaces Compare the translational errors of paths computed with \texttt {A*} and artificial potential fields method\relax }}{75}{figure.caption.84}
\addvspace {10\p@ }
\addvspace {10\p@ }
